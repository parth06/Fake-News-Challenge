{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fnc-transfer_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parth06/Fake-News-Challenge/blob/master/Neural%20Net/fnc_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drUPhvIv7l8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/parth06/Fake-News-Challenge.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU8exY897syJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd Fake-News-Challenge/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEoMVyN7nNKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git submodule init\n",
        "!git submodule update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJdjTxYD7uha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkkz19wd7xCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv2_3yhY7zyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcCrzhiDD8yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6dtz9rH9Ggg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 1\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9ywyRyH8TyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the data directory\n",
        "DATA_DIR = './data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8d2-ApH8Dg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the text files of fnc data\n",
        "bodies = pd.read_csv(DATA_DIR + '/body_id.csv')\n",
        "train_df = pd.read_csv(DATA_DIR + '/train.csv')\n",
        "validation_df = pd.read_csv(DATA_DIR + '/validation.csv')\n",
        "test_df = pd.read_csv(DATA_DIR + '/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWljlMRfKVGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBgcN1Op8PqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bodies.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQnwhONA8W2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmk-UUcd8dQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df[\"Stance\"].head()#value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y-4hI8O-G9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = train_df['Stance'].astype('category').cat.categories.tolist()\n",
        "replace_category = {'Stance' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
        "reverse_labels = {'Stance' : {v: k for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
        "\n",
        "print(replace_category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fi2t92Z-5pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.replace(replace_category, inplace=True)\n",
        "validation_df.replace(replace_category, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ysWmzNZ_GJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYoCtjruJzE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train_df.merge(bodies,on=\"Body ID\")\n",
        "val = validation_df.merge(bodies,on=\"Body ID\")\n",
        "test = test_df.merge(bodies,on=\"Body ID\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vUT3iaHNHlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xtest_overlap = gen_or_load_feats(word_overlap_features, test[\"Headline\"], test[\"articleBody\"], \"features/overlap.train.npy\")\n",
        "# Xtest_refuting = gen_or_load_feats(refuting_features,test[\"Headline\"], test[\"articleBody\"], \"features/refuting.train.npy\")\n",
        "# Xtest_polarity = gen_or_load_feats(polarity_features, test[\"Headline\"], test[\"articleBody\"], \"features/polarity.train.npy\")\n",
        "# Xtest_hand = gen_or_load_feats(hand_features, test[\"Headline\"], test[\"articleBody\"], \"features/hand.train.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnQ8RYcOf-Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAq4rpSXnJ6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train.drop(labels=\"Body ID\",axis=1,inplace=True)\n",
        "# val.drop(labels=\"Body ID\",axis=1,inplace=True)\n",
        "# test.drop(labels=\"Body ID\",axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N0U_vh3neaX",
        "colab_type": "code",
        "outputId": "0a35aecc-8906-46ea-d4c8-aa63d37d92a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "      <th>articleBody</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hundreds of Palestinians flee floods in Gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It's 'rubbish' that Robert Plant turned down £...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Robert Plant ripped up $800M Led Zeppelin reun...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ISIS Militant “Jihadi John” Identified As Youn...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Claim: Comcast Got Complaining Customer Fired ...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>Hundreds of Palestinians were evacuated from t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  ...                                        articleBody\n",
              "0  Hundreds of Palestinians flee floods in Gaza a...  ...  Hundreds of Palestinians were evacuated from t...\n",
              "1  It's 'rubbish' that Robert Plant turned down £...  ...  Hundreds of Palestinians were evacuated from t...\n",
              "2  Robert Plant ripped up $800M Led Zeppelin reun...  ...  Hundreds of Palestinians were evacuated from t...\n",
              "3  ISIS Militant “Jihadi John” Identified As Youn...  ...  Hundreds of Palestinians were evacuated from t...\n",
              "4  Claim: Comcast Got Complaining Customer Fired ...  ...  Hundreds of Palestinians were evacuated from t...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu2vUEmYokLj",
        "colab_type": "code",
        "outputId": "c7749e77-1dc1-4936-b6b1-875fafdab54f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guFmDRHioxvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing involves removal of puctuations and converting text to lower case\n",
        "train[\"Headline\"] = [text_to_word_sequence(head) for head in train['Headline']]\n",
        "train[\"articleBody\"] = [text_to_word_sequence(body) for body in train['articleBody']]\n",
        "val[\"Headline\"] = [text_to_word_sequence(head) for head in val['Headline']]\n",
        "val[\"articleBody\"] = [text_to_word_sequence(body) for body in val['articleBody']]\n",
        "test[\"Headline\"] = [text_to_word_sequence(head) for head in test['Headline']]\n",
        "test[\"articleBody\"] = [text_to_word_sequence(body) for body in test['articleBody']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJWKYu0Ezoml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.Headline = train.Headline.apply(\" \".join)\n",
        "train.articleBody = train.articleBody.apply(\" \".join)\n",
        "val.Headline = val.Headline.apply(\" \".join)\n",
        "val.articleBody = val.articleBody.apply(\" \".join)\n",
        "test.Headline = test.Headline.apply(\" \".join)\n",
        "test.articleBody = test.articleBody.apply(\" \".join)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf1eVbyc0iJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unrelated:1 Related:0\n",
        "def f(row):\n",
        "    if row['Stance']==4:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "train['Classify'] = train.apply(f, axis=1)\n",
        "val['Classify'] = val.apply(f, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T51oLFkBvcoJ",
        "colab_type": "code",
        "outputId": "2b966a13-051c-4ac8-904b-98cd8d07b801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train[\"Classify\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    29647\n",
              "0    10703\n",
              "Name: Classify, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64Jx-Zov2M3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nHUNoFq4cYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGGW5DXl6vRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"inner\"]=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiLyR_7W-Gum",
        "colab_type": "code",
        "outputId": "69683094-8127-4871-d623-f5e40e625e62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "bodies[\"emb\"] = -1\n",
        "bodies.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>A small meteorite crashed into a wooded area i...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Al-Sisi has denied Israeli reports stating tha...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>A bereaved Afghan mother took revenge on the T...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>CNBC is reporting Tesla has chosen Nevada as t...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Last week we hinted at what was to come as Ebo...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Body ID                                        articleBody  emb\n",
              "0        0  A small meteorite crashed into a wooded area i...   -1\n",
              "1        1  Al-Sisi has denied Israeli reports stating tha...   -1\n",
              "2        2  A bereaved Afghan mother took revenge on the T...   -1\n",
              "3        3  CNBC is reporting Tesla has chosen Nevada as t...   -1\n",
              "4        4  Last week we hinted at what was to come as Ebo...   -1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR5or3QJKjvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUDvtXoRKufA",
        "colab_type": "code",
        "outputId": "16940d7d-0162-4bc0-e42c-b523935700a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embed.get_attached_message"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.get_attached_message of <tensorflow_hub.module.Module object at 0x7fd84fb83da0>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UUQ8sJV937T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute a representation for each message, showing various lengths supported.\n",
        "l = len(train)\n",
        "#for i in range(0,l):\n",
        "messages = [train[\"Headline\"][i] for i in range(0,l)]\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "emb = list()\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(messages))\n",
        "\n",
        "  for j, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "    emb.append(message_embedding)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEXjcMazOpAb",
        "colab_type": "code",
        "outputId": "38a888fe-b39d-4559-dfc8-3d2a564f56fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(emb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40350"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUIl-ZeV3PId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute a representation for each message, showing various lengths supported.\n",
        "l = len(bodies)\n",
        "#for i in range(0,l):\n",
        "messages = [bodies[\"articleBody\"][i][:300] for i in range(0,l)]\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "emb2 = list()\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(messages))\n",
        "\n",
        "  for j, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "    emb2.append(message_embedding)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjNYTcSYMzwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"embh\"] = emb\n",
        "bodies[\"embb\"] = emb2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjYpbaH64pgS",
        "colab_type": "code",
        "outputId": "6f234d8c-03ce-4500-d3dd-37b519441f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "df = pd.merge(train,bodies[['Body ID','embb']],on='Body ID', how='left')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Classify</th>\n",
              "      <th>embh</th>\n",
              "      <th>embb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.05026805400848389, -0.005613733548671007, ...</td>\n",
              "      <td>[-0.035615868866443634, -0.04305685684084892, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it's 'rubbish' that robert plant turned down £...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.06691830605268478, 0.05369390547275543, 0.0...</td>\n",
              "      <td>[-0.035615868866443634, -0.04305685684084892, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>robert plant ripped up 800m led zeppelin reuni...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.044021785259246826, 0.010502968914806843, -...</td>\n",
              "      <td>[-0.035615868866443634, -0.04305685684084892, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>isis militant “jihadi john” identified as youn...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.03243670612573624, -0.06309863179922104, -0...</td>\n",
              "      <td>[-0.035615868866443634, -0.04305685684084892, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>claim comcast got complaining customer fired f...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.020369600504636765, 0.05546443909406662, -0...</td>\n",
              "      <td>[-0.035615868866443634, -0.04305685684084892, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  ...                                               embb\n",
              "0  hundreds of palestinians flee floods in gaza a...  ...  [-0.035615868866443634, -0.04305685684084892, ...\n",
              "1  it's 'rubbish' that robert plant turned down £...  ...  [-0.035615868866443634, -0.04305685684084892, ...\n",
              "2  robert plant ripped up 800m led zeppelin reuni...  ...  [-0.035615868866443634, -0.04305685684084892, ...\n",
              "3  isis militant “jihadi john” identified as youn...  ...  [-0.035615868866443634, -0.04305685684084892, ...\n",
              "4  claim comcast got complaining customer fired f...  ...  [-0.035615868866443634, -0.04305685684084892, ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Txl8ojHxkX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embb = list(df.loc[:,\"embb\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59XL0uSRrcpM",
        "colab_type": "code",
        "outputId": "93481a72-1291-4ff6-f042-920cbe8ac5d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import codecs\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import plot_model \n",
        "from IPython.display import Image\n",
        "import pydot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "#from keras import initializations\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "tf_gpu_options = tf.GPUOptions(allow_growth = True) # per_process_gpu_memory_fraction=0.12,\n",
        "tf_session = tf.Session(config=tf.ConfigProto(gpu_options=tf_gpu_options))\n",
        "tf.keras.backend.set_session(tf_session)\n",
        "\n",
        "#biodirectional embedding\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeKH95VZj8Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(merged_model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hqzrs0jrVjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1_in = Input(shape=(512,))\n",
        "model1_out = (model1_in)\n",
        "model1 = Model(model1_in, model1_out)\n",
        "\n",
        "model2_in = Input(shape=(512,))\n",
        "model2_out = (model2_in)\n",
        "model2 = Model(model2_in, model2_out)\n",
        "\n",
        "\n",
        "concatenated = concatenate([model1_out, model2_out])\n",
        "layer_1 = Dense(256, activation='relu', name='layer_1') (concatenated)\n",
        "dropout_1 = Dropout(rate=0.5, name='dropout_1')(layer_1)\n",
        "layer_2 =Dense(64,  activation='relu', name='layer_2') (dropout_1)\n",
        "dropout_2 = Dropout(rate=0.5, name='dropout_2')(layer_2)\n",
        "out1 =  Dense(2, activation='softmax', name='output_layer1')(dropout_2)\n",
        "out2 = Dense(4, activation='softmax', name='output_layer2')(dropout_2)\n",
        "\n",
        "losses = {\n",
        "\t\"output_layer1\": \"categorical_crossentropy\",\n",
        "\t\"output_layer2\": \"categorical_crossentropy\",\n",
        "}\n",
        "lossWeights = {\"output_layer1\": 0.25, \"output_layer2\": 0.75}\n",
        "               \n",
        "merged_model = Model([model1_in, model2_in], [out1,out2])\n",
        "merged_model.compile(loss=losses, optimizer='adam', loss_weights=lossWeights,\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOEqt_htr4Fj",
        "colab_type": "code",
        "outputId": "cfc1221e-77b5-4cf3-8058-31eb941cfea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "merged_model.fit([emb, embb], y=[dummy_y_train,dummy_y1_train], batch_size=128, epochs=20, \n",
        "               validation_split=0.1,verbose=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 36315 samples, validate on 4035 samples\n",
            "Epoch 1/20\n",
            "36315/36315 [==============================] - 6s 169us/step - loss: 0.5377 - output_layer1_loss: 0.4156 - output_layer2_loss: 0.5783 - output_layer1_acc: 0.8021 - output_layer2_acc: 0.7927 - val_loss: 0.6331 - val_output_layer1_loss: 0.3380 - val_output_layer2_loss: 0.7315 - val_output_layer1_acc: 0.9036 - val_output_layer2_acc: 0.7093\n",
            "Epoch 2/20\n",
            "36315/36315 [==============================] - 3s 73us/step - loss: 0.2688 - output_layer1_loss: 0.1565 - output_layer2_loss: 0.3062 - output_layer1_acc: 0.9409 - output_layer2_acc: 0.8886 - val_loss: 0.4686 - val_output_layer1_loss: 0.1630 - val_output_layer2_loss: 0.5705 - val_output_layer1_acc: 0.9477 - val_output_layer2_acc: 0.7735\n",
            "Epoch 3/20\n",
            "36315/36315 [==============================] - 3s 75us/step - loss: 0.2093 - output_layer1_loss: 0.1032 - output_layer2_loss: 0.2446 - output_layer1_acc: 0.9615 - output_layer2_acc: 0.9117 - val_loss: 0.4738 - val_output_layer1_loss: 0.1705 - val_output_layer2_loss: 0.5749 - val_output_layer1_acc: 0.9371 - val_output_layer2_acc: 0.7777\n",
            "Epoch 4/20\n",
            "36315/36315 [==============================] - 3s 74us/step - loss: 0.1793 - output_layer1_loss: 0.0790 - output_layer2_loss: 0.2127 - output_layer1_acc: 0.9719 - output_layer2_acc: 0.9250 - val_loss: 0.4510 - val_output_layer1_loss: 0.1469 - val_output_layer2_loss: 0.5524 - val_output_layer1_acc: 0.9485 - val_output_layer2_acc: 0.7926\n",
            "Epoch 5/20\n",
            "36315/36315 [==============================] - 3s 76us/step - loss: 0.1636 - output_layer1_loss: 0.0681 - output_layer2_loss: 0.1955 - output_layer1_acc: 0.9757 - output_layer2_acc: 0.9294 - val_loss: 0.4305 - val_output_layer1_loss: 0.1270 - val_output_layer2_loss: 0.5317 - val_output_layer1_acc: 0.9529 - val_output_layer2_acc: 0.7995\n",
            "Epoch 6/20\n",
            "36315/36315 [==============================] - 3s 74us/step - loss: 0.1523 - output_layer1_loss: 0.0603 - output_layer2_loss: 0.1830 - output_layer1_acc: 0.9782 - output_layer2_acc: 0.9334 - val_loss: 0.4525 - val_output_layer1_loss: 0.1394 - val_output_layer2_loss: 0.5569 - val_output_layer1_acc: 0.9480 - val_output_layer2_acc: 0.7993\n",
            "Epoch 7/20\n",
            "36315/36315 [==============================] - 3s 74us/step - loss: 0.1436 - output_layer1_loss: 0.0543 - output_layer2_loss: 0.1734 - output_layer1_acc: 0.9805 - output_layer2_acc: 0.9374 - val_loss: 0.4619 - val_output_layer1_loss: 0.1346 - val_output_layer2_loss: 0.5710 - val_output_layer1_acc: 0.9529 - val_output_layer2_acc: 0.7990\n",
            "Epoch 8/20\n",
            "36315/36315 [==============================] - 3s 75us/step - loss: 0.1353 - output_layer1_loss: 0.0502 - output_layer2_loss: 0.1636 - output_layer1_acc: 0.9828 - output_layer2_acc: 0.9407 - val_loss: 0.4381 - val_output_layer1_loss: 0.1318 - val_output_layer2_loss: 0.5402 - val_output_layer1_acc: 0.9524 - val_output_layer2_acc: 0.8010\n",
            "Epoch 9/20\n",
            "36315/36315 [==============================] - 3s 75us/step - loss: 0.1305 - output_layer1_loss: 0.0485 - output_layer2_loss: 0.1578 - output_layer1_acc: 0.9835 - output_layer2_acc: 0.9428 - val_loss: 0.4477 - val_output_layer1_loss: 0.1352 - val_output_layer2_loss: 0.5518 - val_output_layer1_acc: 0.9529 - val_output_layer2_acc: 0.7970\n",
            "Epoch 10/20\n",
            "36315/36315 [==============================] - 3s 73us/step - loss: 0.1256 - output_layer1_loss: 0.0450 - output_layer2_loss: 0.1524 - output_layer1_acc: 0.9848 - output_layer2_acc: 0.9437 - val_loss: 0.4670 - val_output_layer1_loss: 0.1508 - val_output_layer2_loss: 0.5724 - val_output_layer1_acc: 0.9477 - val_output_layer2_acc: 0.8002\n",
            "Epoch 11/20\n",
            "36315/36315 [==============================] - 3s 73us/step - loss: 0.1204 - output_layer1_loss: 0.0417 - output_layer2_loss: 0.1466 - output_layer1_acc: 0.9852 - output_layer2_acc: 0.9455 - val_loss: 0.4742 - val_output_layer1_loss: 0.1536 - val_output_layer2_loss: 0.5810 - val_output_layer1_acc: 0.9465 - val_output_layer2_acc: 0.8015\n",
            "Epoch 12/20\n",
            "36315/36315 [==============================] - 3s 73us/step - loss: 0.1121 - output_layer1_loss: 0.0369 - output_layer2_loss: 0.1372 - output_layer1_acc: 0.9878 - output_layer2_acc: 0.9489 - val_loss: 0.4820 - val_output_layer1_loss: 0.1442 - val_output_layer2_loss: 0.5946 - val_output_layer1_acc: 0.9507 - val_output_layer2_acc: 0.7963\n",
            "Epoch 13/20\n",
            "36315/36315 [==============================] - 3s 75us/step - loss: 0.1089 - output_layer1_loss: 0.0357 - output_layer2_loss: 0.1333 - output_layer1_acc: 0.9879 - output_layer2_acc: 0.9496 - val_loss: 0.4891 - val_output_layer1_loss: 0.1415 - val_output_layer2_loss: 0.6050 - val_output_layer1_acc: 0.9546 - val_output_layer2_acc: 0.8097\n",
            "Epoch 14/20\n",
            "36315/36315 [==============================] - 3s 75us/step - loss: 0.1040 - output_layer1_loss: 0.0348 - output_layer2_loss: 0.1271 - output_layer1_acc: 0.9882 - output_layer2_acc: 0.9521 - val_loss: 0.4785 - val_output_layer1_loss: 0.1401 - val_output_layer2_loss: 0.5913 - val_output_layer1_acc: 0.9611 - val_output_layer2_acc: 0.8134\n",
            "Epoch 15/20\n",
            "36315/36315 [==============================] - 3s 74us/step - loss: 0.1020 - output_layer1_loss: 0.0351 - output_layer2_loss: 0.1244 - output_layer1_acc: 0.9879 - output_layer2_acc: 0.9521 - val_loss: 0.4870 - val_output_layer1_loss: 0.1545 - val_output_layer2_loss: 0.5978 - val_output_layer1_acc: 0.9502 - val_output_layer2_acc: 0.8112\n",
            "Epoch 16/20\n",
            "36315/36315 [==============================] - 3s 75us/step - loss: 0.0996 - output_layer1_loss: 0.0325 - output_layer2_loss: 0.1219 - output_layer1_acc: 0.9897 - output_layer2_acc: 0.9548 - val_loss: 0.4902 - val_output_layer1_loss: 0.1550 - val_output_layer2_loss: 0.6019 - val_output_layer1_acc: 0.9494 - val_output_layer2_acc: 0.8102\n",
            "Epoch 17/20\n",
            "36315/36315 [==============================] - 3s 76us/step - loss: 0.0980 - output_layer1_loss: 0.0333 - output_layer2_loss: 0.1195 - output_layer1_acc: 0.9888 - output_layer2_acc: 0.9544 - val_loss: 0.4487 - val_output_layer1_loss: 0.1349 - val_output_layer2_loss: 0.5533 - val_output_layer1_acc: 0.9564 - val_output_layer2_acc: 0.8099\n",
            "Epoch 18/20\n",
            "36315/36315 [==============================] - 3s 76us/step - loss: 0.0908 - output_layer1_loss: 0.0282 - output_layer2_loss: 0.1117 - output_layer1_acc: 0.9900 - output_layer2_acc: 0.9560 - val_loss: 0.5363 - val_output_layer1_loss: 0.1838 - val_output_layer2_loss: 0.6538 - val_output_layer1_acc: 0.9475 - val_output_layer2_acc: 0.8020\n",
            "Epoch 19/20\n",
            "36315/36315 [==============================] - 3s 74us/step - loss: 0.0900 - output_layer1_loss: 0.0273 - output_layer2_loss: 0.1109 - output_layer1_acc: 0.9909 - output_layer2_acc: 0.9575 - val_loss: 0.4934 - val_output_layer1_loss: 0.1561 - val_output_layer2_loss: 0.6058 - val_output_layer1_acc: 0.9529 - val_output_layer2_acc: 0.8136\n",
            "Epoch 20/20\n",
            "36315/36315 [==============================] - 3s 74us/step - loss: 0.0878 - output_layer1_loss: 0.0270 - output_layer2_loss: 0.1080 - output_layer1_acc: 0.9906 - output_layer2_acc: 0.9575 - val_loss: 0.4792 - val_output_layer1_loss: 0.1585 - val_output_layer2_loss: 0.5861 - val_output_layer1_acc: 0.9559 - val_output_layer2_acc: 0.8141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f436925fb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y85scoixD6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = df['Stance']\n",
        "#y_val = combine_df_validation['Stance']\n",
        "#Encode class values as integers\n",
        "encoder_train = LabelEncoder()\n",
        "encoder_train.fit(y_train)\n",
        "encoded_train = encoder_train.transform(y_train)\n",
        "#encoded_val = encoder_train.transform(y_val)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y1_train = np_utils.to_categorical(encoded_train)\n",
        "#dummy_y_val = np_utils.to_categorical(encoded_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UY9-E251sWU",
        "colab_type": "code",
        "outputId": "4669ec86-5da3-468f-9126-e349665ffb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "dummy_y1_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukkn0UP_UQGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = len(df)\n",
        "ans = list()\n",
        "for i in range(0,l):\n",
        "  ans.append(np.inner(df.embh[i],df.embb[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSAT2JrLU5-c",
        "colab_type": "code",
        "outputId": "64534e23-2925-40a5-affc-7856e829a98a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "df.inner = ans\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Classify</th>\n",
              "      <th>inner</th>\n",
              "      <th>embh</th>\n",
              "      <th>embb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.815439</td>\n",
              "      <td>[-0.05026805400848389, -0.005613733548671007, ...</td>\n",
              "      <td>[-0.0466877780854702, -0.010597342625260353, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it's 'rubbish' that robert plant turned down £...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.242716</td>\n",
              "      <td>[0.06691830605268478, 0.05369390547275543, 0.0...</td>\n",
              "      <td>[-0.0466877780854702, -0.010597342625260353, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>robert plant ripped up 800m led zeppelin reuni...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114176</td>\n",
              "      <td>[0.044021785259246826, 0.010502968914806843, -...</td>\n",
              "      <td>[-0.0466877780854702, -0.010597342625260353, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>isis militant “jihadi john” identified as youn...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.315851</td>\n",
              "      <td>[0.03243670612573624, -0.06309863179922104, -0...</td>\n",
              "      <td>[-0.0466877780854702, -0.010597342625260353, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>claim comcast got complaining customer fired f...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.188835</td>\n",
              "      <td>[0.020369600504636765, 0.05546443909406662, -0...</td>\n",
              "      <td>[-0.0466877780854702, -0.010597342625260353, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  ...                                               embb\n",
              "0  hundreds of palestinians flee floods in gaza a...  ...  [-0.0466877780854702, -0.010597342625260353, -...\n",
              "1  it's 'rubbish' that robert plant turned down £...  ...  [-0.0466877780854702, -0.010597342625260353, -...\n",
              "2  robert plant ripped up 800m led zeppelin reuni...  ...  [-0.0466877780854702, -0.010597342625260353, -...\n",
              "3  isis militant “jihadi john” identified as youn...  ...  [-0.0466877780854702, -0.010597342625260353, -...\n",
              "4  claim comcast got complaining customer fired f...  ...  [-0.0466877780854702, -0.010597342625260353, -...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYE2cpvpVPHD",
        "colab_type": "code",
        "outputId": "c6cfbc6c-2ab9-4acb-d27b-53003c20072d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df[df.inner<0.45][\"Classify\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    25824\n",
              "0      429\n",
              "Name: Classify, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQVgHN2UWCMQ",
        "colab_type": "code",
        "outputId": "5b408365-b0ac-4e33-89be-d967dab19535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df[df.inner>0.45][\"Stance\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    6886\n",
              "4    3823\n",
              "1    2758\n",
              "2     630\n",
              "Name: Stance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKSmdMdeXCfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# indexNames = df[ df.inner<0.45 ].index\n",
        " \n",
        "# # Delete these row indexes from dataFrame\n",
        "# df.drop(indexNames , inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F06lYpm7Y1Ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAAfwSboYU93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute a representation for each message, showing various lengths supported.\n",
        "l = len(test)\n",
        "#for i in range(0,l):\n",
        "messages = [test[\"Headline\"][i] for i in range(0,l)]\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "emb3 = list()\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(messages))\n",
        "\n",
        "  for j, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "    emb3.append(message_embedding)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRMt7_1rYU5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[\"embh\"] = emb3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8P7Ir9ZdWVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.merge(test,bodies[['Body ID','embb']],on='Body ID', how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uR_EtwS0A4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embbt = list(test.loc[:,\"embb\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIRFoK9VznjV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b = merged_model.predict([emb3,embbt])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RlfumNO0k1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = np.argmax(a,axis=1)\n",
        "b = np.argmax(b,axis=1)\n",
        "pred=list()\n",
        "for i in range(0,len(a)):\n",
        "  if a[i]==1: #unrelated\n",
        "    pred.append(3)\n",
        "  elif a[i]==0 and b[i]==4:\n",
        "    pred.append(4)\n",
        "  else:\n",
        "    pred.append(b[i])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvg6XRV90nv-",
        "colab_type": "code",
        "outputId": "eaaff7e4-887b-4724-b1f0-f5a8efb4a63a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ans = pd.DataFrame(pred)\n",
        "ans.replace(3,'unrelated',True)\n",
        "ans.replace(0,'agree',True)\n",
        "ans.replace(1,'disagree',True)\n",
        "ans.replace(2,'discuss',True)\n",
        "ans.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0    discuss\n",
              "1  unrelated\n",
              "2  unrelated\n",
              "3  unrelated\n",
              "4    discuss"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dv5JF3C0wrm",
        "colab_type": "code",
        "outputId": "95f1ab92-f37e-40a6-eb23-a17fec1d360a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from feature_engineering import refuting_features, polarity_features, hand_features, gen_or_load_feats\n",
        "from feature_engineering import word_overlap_features\n",
        "from utils.dataset import DataSet\n",
        "from utils.generate_test_splits import kfold_split, get_stances_for_folds\n",
        "from utils.score import report_score, LABELS, score_submission\n",
        "\n",
        "from utils.system import parse_params, check_version\n",
        "def generate_features(stances,dataset,name):\n",
        "    h, b, y = [],[],[]\n",
        "\n",
        "    for stance in stances:\n",
        "        y.append(LABELS.index(stance['Stance']))\n",
        "        h.append(stance['Headline'])\n",
        "        b.append(dataset.articles[stance['Body ID']])\n",
        "\n",
        "    return y\n",
        "  \n",
        "\n",
        "competition_dataset = DataSet(\"competition_test\")\n",
        "y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
        "\n",
        "Xs = dict()\n",
        "ys = dict()\n",
        "\n",
        "# Load/Precompute all features now\n",
        "#Run on competition dataset\n",
        "actual = [LABELS[int(a)] for a in y_competition]\n",
        "\n",
        "print(\"Scores on the test set\")\n",
        "report_score(actual,ans[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dataset\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n",
            "Scores on the test set\n",
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    216    |     0     |    373    |   1314    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    107    |     0     |    150    |    440    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    432    |     0     |    775    |   3257    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |   1766    |     0     |   3078    |   13505   |\n",
            "-------------------------------------------------------------\n",
            "Score: 4632.75 out of 11651.25\t(39.76182813002897%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39.76182813002897"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nll01hltdk-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = len(test)\n",
        "anst = list()\n",
        "for i in range(0,l):\n",
        "  anst.append(np.inner(test.embh[i],test.embb[i]))\n",
        "test[\"inner\"] = anst"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pmX1iXydiTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[\"Stance\"]=-1\n",
        "for i in range(0,len(test)):\n",
        "  if test.inner[i] <0.45:\n",
        "    test.loc[i,\"Stance\"]=4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsJvaaJndRVP",
        "colab_type": "code",
        "outputId": "2cab068d-0b55-40d5-e98b-84abc90ba6e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>embh</th>\n",
              "      <th>embb</th>\n",
              "      <th>inner</th>\n",
              "      <th>Stance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ferguson riots pregnant woman loses eye after ...</td>\n",
              "      <td>2008</td>\n",
              "      <td>a respected senior french police officer inves...</td>\n",
              "      <td>[-0.06295444816350937, -0.07035506516695023, -...</td>\n",
              "      <td>[0.0317782461643219, -0.050620388239622116, -0...</td>\n",
              "      <td>0.523870</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apple stores to install safes to secure gold a...</td>\n",
              "      <td>2008</td>\n",
              "      <td>a respected senior french police officer inves...</td>\n",
              "      <td>[0.03951696306467056, -0.049585841596126556, -...</td>\n",
              "      <td>[0.0317782461643219, -0.050620388239622116, -0...</td>\n",
              "      <td>0.157018</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pregnant woman loses eye after police shoot be...</td>\n",
              "      <td>2008</td>\n",
              "      <td>a respected senior french police officer inves...</td>\n",
              "      <td>[-0.07143513113260269, -0.0795423835515976, -0...</td>\n",
              "      <td>[0.0317782461643219, -0.050620388239622116, -0...</td>\n",
              "      <td>0.420942</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we just found out the ferguson protester who c...</td>\n",
              "      <td>2008</td>\n",
              "      <td>a respected senior french police officer inves...</td>\n",
              "      <td>[-0.04828790947794914, 0.009491262026131153, -...</td>\n",
              "      <td>[0.0317782461643219, -0.050620388239622116, -0...</td>\n",
              "      <td>0.466931</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>police chief in charge of paris attacks commit...</td>\n",
              "      <td>2008</td>\n",
              "      <td>a respected senior french police officer inves...</td>\n",
              "      <td>[0.02026490867137909, -0.05242277309298515, -0...</td>\n",
              "      <td>[0.0317782461643219, -0.050620388239622116, -0...</td>\n",
              "      <td>0.730503</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  Body ID  ...     inner Stance\n",
              "0  ferguson riots pregnant woman loses eye after ...     2008  ...  0.523870     -1\n",
              "1  apple stores to install safes to secure gold a...     2008  ...  0.157018      4\n",
              "2  pregnant woman loses eye after police shoot be...     2008  ...  0.420942      4\n",
              "3  we just found out the ferguson protester who c...     2008  ...  0.466931     -1\n",
              "4  police chief in charge of paris attacks commit...     2008  ...  0.730503     -1\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os8PXp9qhDG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = [int(a) for a in clf.predict(X)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPjTiBuhDCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "j=0\n",
        "for i in range(0,len(test)):\n",
        "  if test.Stance[i]==-1:\n",
        "    if test.inner > 0.85 and predicted[j]==4:\n",
        "      test.loc[i,\"Stance\"]=3\n",
        "    else:\n",
        "      test.loc[i,\"Stance\"]=predicted[j]\n",
        "    j=j+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RmQqY5QmTSQ",
        "colab_type": "code",
        "outputId": "b29d48db-d3ac-4a2d-db14-5da592440e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "test.Stance.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "unrelated    19475\n",
              "discuss       5519\n",
              "agree          395\n",
              "disagree        24\n",
              "Name: Stance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzkriPVwmPLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labels = ['Stance'].astype('category').cat.categories.tolist()\n",
        "# replace_category = {'Stance' : {k: v for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
        "# reverse_labels = {'Stance' : {v: k for k,v in zip(labels,list(range(1,len(labels)+1)))}}\n",
        "\n",
        "# print(replace_category)\n",
        "\n",
        "test.replace(reverse_labels, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_6amnjDnchD",
        "colab_type": "code",
        "outputId": "11308b7d-4c45-4e7d-a9e8-5dccdc7809dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from feature_engineering import refuting_features, polarity_features, hand_features, gen_or_load_feats\n",
        "from feature_engineering import word_overlap_features\n",
        "from utils.dataset import DataSet\n",
        "from utils.generate_test_splits import kfold_split, get_stances_for_folds\n",
        "from utils.score import report_score, LABELS, score_submission\n",
        "\n",
        "from utils.system import parse_params, check_version\n",
        "def generate_features(stances,dataset,name):\n",
        "    h, b, y = [],[],[]\n",
        "\n",
        "    for stance in stances:\n",
        "        y.append(LABELS.index(stance['Stance']))\n",
        "        h.append(stance['Headline'])\n",
        "        b.append(dataset.articles[stance['Body ID']])\n",
        "\n",
        "    return y\n",
        "  \n",
        "\n",
        "competition_dataset = DataSet(\"competition_test\")\n",
        "y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
        "\n",
        "Xs = dict()\n",
        "ys = dict()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dataset\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G24xDeGXneXn",
        "colab_type": "code",
        "outputId": "fcfc9f7d-70d2-4bb7-fe8f-9a8aefb3e987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Run on competition dataset\n",
        "actual = [LABELS[int(a)] for a in y_competition]\n",
        "\n",
        "print(\"Scores on the test set\")\n",
        "report_score(actual,pred)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores on the test set\n",
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    33     |     1     |    454    |   1415    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    17     |     2     |    201    |    477    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    64     |     6     |    995    |   3399    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    281    |    15     |   3869    |   14184   |\n",
            "-------------------------------------------------------------\n",
            "Score: 4761.75 out of 11651.25\t(40.86900547151593%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40.86900547151593"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHiuE894nc2C",
        "colab_type": "code",
        "outputId": "1fedfcb2-c932-4d71-a4e7-d7eda1a22b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Body ID</th>\n",
              "      <th>Stance</th>\n",
              "      <th>articleBody</th>\n",
              "      <th>Classify</th>\n",
              "      <th>inner</th>\n",
              "      <th>embh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hundreds of palestinians flee floods in gaza a...</td>\n",
              "      <td>158</td>\n",
              "      <td>1</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>[-0.05026805400848389, -0.005613733548671007, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it's 'rubbish' that robert plant turned down £...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>[0.06691830605268478, 0.05369390547275543, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>robert plant ripped up 800m led zeppelin reuni...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>[0.044021785259246826, 0.010502968914806843, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>isis militant “jihadi john” identified as youn...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>[0.03243670612573624, -0.06309863179922104, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>claim comcast got complaining customer fired f...</td>\n",
              "      <td>158</td>\n",
              "      <td>4</td>\n",
              "      <td>hundreds of palestinians were evacuated from t...</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>[0.020369600504636765, 0.05546443909406662, -0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline  ...                                               embh\n",
              "0  hundreds of palestinians flee floods in gaza a...  ...  [-0.05026805400848389, -0.005613733548671007, ...\n",
              "1  it's 'rubbish' that robert plant turned down £...  ...  [0.06691830605268478, 0.05369390547275543, 0.0...\n",
              "2  robert plant ripped up 800m led zeppelin reuni...  ...  [0.044021785259246826, 0.010502968914806843, -...\n",
              "3  isis militant “jihadi john” identified as youn...  ...  [0.03243670612573624, -0.06309863179922104, -0...\n",
              "4  claim comcast got complaining customer fired f...  ...  [0.020369600504636765, 0.05546443909406662, -0...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtN2cKtUzwtd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from numpy import array\n",
        "# define model where LSTM is also output layer\n",
        "model1 = Sequential()\n",
        "model1.add(LSTM(1, input_shape=(1,512)))\n",
        "model1.compile(optimizer='adam', loss='mse')\n",
        "# input time steps\n",
        "# make and show prediction\n",
        "print(model1.predict(train[[\"embh\",\"Stance\"]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H24sk4r_YP7I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVAfAvNPuYKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train[\"Headline\"] = train[\"Headline\"].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "train[\"articleBody\"] =train['articleBody'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "val[\"Headline\"] = val['Headline'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "val[\"articleBody\"] = val['articleBody'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "test[\"Headline\"] = test['Headline'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "test[\"articleBody\"] = test['articleBody'].apply(lambda x: [item for item in x if item not in stop_words])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLzIgdT7vqga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUK1-ZZmq4AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('90th Percentile Sentence of headline:', np.percentile([len(seq) for seq in train[\"Headline\"]], 90))\n",
        "print('90th Percentile Sentence of body:', np.percentile([len(seq) for seq in train[\"articleBody\"]], 50))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}